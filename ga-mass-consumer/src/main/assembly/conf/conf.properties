#commonns config  
application.name=ImcaptureApp
#kafka conf
kafka.zk.url=rzx162:2181,rzx164:2181,rzx166:2181/kafka
kafka.group.id=helloworld999
# 以下是会监听报警的所有 topic
kafka.topic=wl_001|fj_001|xw_001|sj_001|tz_001

#jdbc config
jdbc.url=jdbc:mysql://192.168.0.183:3306/gacenter?useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull
jdbc.username=root
jdbc.password=surfilter1218

#redis config
redis.url=192.168.0.166|6379

# kafka partition number, default value is 5
kafka.partition.num=5

# the json2Kafka topic's parse length
# 以下的解析字段个数对应的都是 json2Kafka 的字段个数，每次 json2Kafka 加了字段，就要修改对应的值
# 对应每次版本的更新，值应该相应的更新，此处采用默认配置
# 一般情况下值的长度为对应存储原始日志的长度减去2(除非 json2Kafka 没加字段，而原始日志加了字段)
# wl 对应的解析字段个数
match.parse.wl.length=34
# fj 对应的解析字段个数
match.parse.fj.length=48
# xw 对应的解析字段个数
match.parse.xw.length=42
# sj 对应的解析字段个数
match.parse.sj.length=46
# tz 对应的解析字段个数
match.parse.tz.length=28

# Duplicate data 
# If the value is 1 then will heavy discharge in redis.
# 指定报警是否按天进行排重
# 如果值为1，表明是按天进行排重，会对报警次数及 endTime 为0的数据使用报警时间间隔限制
# 如果设置为其他值，表明不按天进行排重，报警次数限制会失效，endTime 为0的数据时间间隔报警也会失效
match.duplicate.remove=1
#match information
# pool size
# 消费线程数量
match.thread.size=10
# the cache every {num} minutes flush, default value is 5.
# 数据库查询的匹配条件缓存时间间隔，默认值是5分钟
match.init.interval=5

# the alarm info within {num} minutes base on start time will be alarmed
# default value is 180 minutes in coding and setting, if the {num} is illegal than default value is 180
# the value must is >= 0, otherwise will not alarm
# 只处理发生时间在当前时间 180 分钟范围内的数据
alarm.info.days.between=180

# 该参数用于限制 endTime 为0的数据
# 如果数据的 endTime 为0，则距离最近一次的报警时间间隔默认是 300 秒
# 如果两个报警时间在300秒内即5分钟内，说明报警的数据中，至少有一个 endTime 不为0
alarm.max.interval.seconds=300

#数据库查询场所信息缓存间隔时间（单位为分钟），默认为60分钟
service.info.reload.minutes=60